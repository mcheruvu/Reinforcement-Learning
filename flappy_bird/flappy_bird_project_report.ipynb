{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flappy Bird Project: Compare Various RL Algorithms\n",
    "\n",
    "\n",
    "## Course: Summer 2018, Deep Reinforcement Learning\n",
    "\n",
    "**Professor: Dr. James Shanahan**\n",
    "\n",
    "**TA: Christopher Dailey**\n",
    "\n",
    "**Students: Gelesh Omathil, Naveen Kaul, Murali Cheruvu**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Details: \n",
    "\n",
    "## Goal:\n",
    "Produce a Table of RL-based approaches - Tabular and Value Approximations, where each row is an approach and each column is a dimension that differentiates the approaches such as model free, which of the quintuple each uses (State, Action, Transitions,  Rewards, etc..), and other dimensions.\n",
    "\n",
    "## Flappy Bird Game:\n",
    "Flappybird is a side-scrolling game where the agent must successfully navigate through gaps between pipes. The up arrow causes the bird to accelerate upwards. If the bird makes contact with the ground or pipes, or goes above the top of the screen, the game is over. For each pipe it passes through it gains a positive reward. Each time a terminal state is reached it receives a negative reward.\n",
    "\n",
    "Determine a good policy for Flappy Birds using  any one or more of the following algorithms (aim to get 140 points or more!):\n",
    "* Policy Iteration, Value Iteration, Q Learning, TD, Monte Carlo\n",
    "\n",
    "You may have to discretize the  space of  following parameters.\n",
    "* Vertical distance from lower pipe\n",
    "* Horizontal distance from next pair of pipes\n",
    "* Life: Dead or Living\n",
    "### Actions\n",
    "For each state, there two possible actions\n",
    "* Up\n",
    "* Down\n",
    "### Rewards\n",
    "The reward structure is purely based on the \"Life\" parameter. One possible such structure could be the following (feel free to explore more):\n",
    "* **+1** if Flappy Bird is still alive\n",
    "* **-1000** if Flappy Bird is dead\n",
    "\n",
    "## Flappy Birds Simulator:\n",
    "Please use the openai gym environment for this project:\n",
    "\n",
    "* https://gym.openai.com/envs/FlappyBird-v0/\n",
    "\n",
    "\n",
    "## Submission\n",
    "\n",
    "Please submit a report notebook and the python code-base for the algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Algorithms\n",
    "\n",
    "## List of Algorithms\n",
    "\n",
    "We have implemented the following algorithms to train and play the flappy bird game:\n",
    "\n",
    "* Tabular: Q-Learning\n",
    "* Value Approximator: Linear Regression\n",
    "* Value Approximator: Simple Q-Learning Network\n",
    "* Value Approximator: Deep Q-Learning Network\n",
    "\n",
    "**Note: Please refer to each of the above Jupyter Notebooks for the algorithm concepts, details and implementation**\n",
    "\n",
    "## Technologies Used:\n",
    "\n",
    "* Python - Keras, TensorFlow and standard libraries\n",
    "* PyGame and Open AI Gym for Game Environment\n",
    "* Open AI Gym complaint Flappy Bird Environment\n",
    "* GPU enabled Cloud to run the Deep Q-Learning Network algorithm (using Microsoft Azure Windows Platform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms: Metrics and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References: \n",
    "\n",
    "**We would like thank our professor: Dr. Shanahan and TA, Chris Dailey for their great guidance and continual help and support during the Deep Reinforcement Learning course.**\n",
    "\n",
    "**We would also like to thank various developers and authors of the Reinforcement Learning related including the references given in the following links.**\n",
    "\n",
    "https://medium.com/@videshsuman/using-reinforcement-learning-techniques-to-build-an-ai-bot-for-the-game-flappy-bird-30e0fd22f990\n",
    "\n",
    "\n",
    "https://hardikbansal.github.io/FlappyDQNBlog/\n",
    "https://github.com/chncyhn/flappybird-qlearning-bot\n",
    "\n",
    "https://github.com/yenchenlin/DeepLearningFlappyBird\n",
    "\n",
    "https://github.com/aronszanto/Flappy-Bird-Learning/blob/master/FB%20White%20Paper.pdf\n",
    "\n",
    "https://github.com/rabbitnoname/rlsimple/blob/master/DQN/deep_q_network.py\n",
    "\n",
    "https://github.com/floodsung/Gym-Flappy-Bird/blob/master/gym_flappy_bird/envs/flappy_bird_env.py\n",
    "\n",
    "https://github.com/SupaeroDataScience/RLchallenge/blob/master/RandomBird/FlappyAgent.py\n",
    "\n",
    "https://github.com/ntasfi/PyGame-Learning-Environment/blob/master/docs/user/home.rst\n",
    "\n",
    "https://nthu-datalab.github.io/ml/labs/16-1_Q-Learning/16-1_Q_Learning.html\n",
    "\n",
    "http://karpathy.github.io/2016/05/31/rl/\n",
    "\n",
    "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0\n",
    "\n",
    "https://github.com/mebusy/notes/blob/master/dev_notes/RL_DavidSilver.md\n",
    "\n",
    "https://github.com/fiezt/Reinforcement-Learning/blob/master/code/OpenAIGymExamples.ipynb\n",
    "\n",
    "https://github.com/mpatacchiola/dissecting-reinforcement-learning/blob/master/src/6/multi-armed-bandit/epsilon_greedy_agent_bandit.py\n",
    "\n",
    "https://dunglai.github.io/2017/09/21/FlappyBirdAI/\n",
    "\n",
    "https://blog.openai.com/evolution-strategies/\n",
    "\n",
    "http://blog.aylien.com/flappy-bird-and-evolution-strategies-an-experiment/\n",
    "\n",
    "https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html\n",
    "\n",
    "https://dunglai.github.io/2017/10/10/linear-regression/\n",
    "\n",
    "\n",
    "https://github.com/dalmia/David-Silver-Reinforcement-learning/blob/master/Week%206%20-%20Value%20Function%20Approximations/Q-Learning%20with%20Value%20Function%20Approximation.ipynb\n",
    "\n",
    "https://github.com/floodsung/Gym-Flappy-Bird/blob/master/gym_flappy_bird/envs/flappy_bird_env.py\n",
    "\n",
    "https://github.com/jmathison/gym-simpleflappy\n",
    "\n",
    "\n",
    "https://tonypoer.io/2016/12/15/making-an-ai-to-play-flappy-bird-w-q-learning/\n",
    "\n",
    "https://medium.com/@jamsawamsa/running-a-google-cloud-gpu-for-fast-ai-for-free-5f89c707bae6\n",
    "\n",
    "https://github.com/ssusnic/Machine-Learning-Flappy-Bird\n",
    "\n",
    "http://burlap.cs.brown.edu/tutorials_v2/scd/p1.html\n",
    "\n",
    "https://github.com/keon/deep-q-learning/blob/master/dqn.py\n",
    "\n",
    "https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c\n",
    "\n",
    "https://github.com/yenchenlin/DeepLearningFlappyBird\n",
    "\n",
    "https://medium.com/@gtnjuvin/my-journey-into-deep-q-learning-with-keras-and-gym-3e779cc12762\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
